

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Estimators (classification and regression) &mdash; REP (Reproducible Experiment Platform) 0.6.7 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="REP (Reproducible Experiment Platform) 0.6.7 documentation" href="index.html"/>
        <link rel="next" title="Meta Machine Learning" href="metaml.html"/>
        <link rel="prev" title="Welcome to REP’s documentation!" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> REP (Reproducible Experiment Platform)
          

          
          </a>

          
            
            
              <div class="version">
                0.6.7
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="">Estimators (classification and regression)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.interface">Estimators interfaces (for classification and regression)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.sklearn">Sklearn classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.tmva">TMVA classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.xgboost">XGBoost classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.theanets">Theanets classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.neurolab">Neurolab classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.pybrain">Pybrain classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rep.estimators.matrixnet">MatrixNet classifier and regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#classification">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="#regression">Regression</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#compatible-libraries">Compatible libraries</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metaml.html">Meta Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="report.html">Report for models</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">Plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel.html">Parallel computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="reproducibility.html">REProducibility</a></li>
<li class="toctree-l1"><a class="reference external" href="http://nbviewer.ipython.org/github/yandex/rep/tree/master/howto/">Howto notebooks</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">REP (Reproducible Experiment Platform)</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Estimators (classification and regression)</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/estimators.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="estimators-classification-and-regression">
<span id="estimators"></span><h1>Estimators (classification and regression)<a class="headerlink" href="#estimators-classification-and-regression" title="Permalink to this headline">¶</a></h1>
<p>This module contains wrappers with <code class="xref py py-class docutils literal"><span class="pre">sklearn</span></code> interface for different machine learning libraries:</p>
<blockquote>
<div><ul class="simple">
<li>scikit-learn</li>
<li>TMVA</li>
<li>XGBoost</li>
<li>pybrain</li>
<li>neurolab</li>
<li>theanets.</li>
</ul>
</div></blockquote>
<p><strong>REP</strong> defines interface for classifiers&#8217; and regressors&#8217; wrappers, thus new wrappers can be added for another libraries
following the same interface. Notably the interface has backward compatibility with scikit-learn library.</p>
<div class="section" id="module-rep.estimators.interface">
<span id="estimators-interfaces-for-classification-and-regression"></span><h2>Estimators interfaces (for classification and regression)<a class="headerlink" href="#module-rep.estimators.interface" title="Permalink to this headline">¶</a></h2>
<p><strong>REP</strong> wrappers are derived from <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">Classifier</span></code></a> and <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">Regressor</span></code></a>
depending on the problem of interest.</p>
<p>Below you can see the standard methods available in the wrappers.</p>
<dl class="class">
<dt id="rep.estimators.interface.Classifier">
<em class="property">class </em><code class="descclassname">rep.estimators.interface.</code><code class="descname">Classifier</code><span class="sig-paren">(</span><em>features=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.ClassifierMixin</span></code></p>
<p>Interface to train different <strong>classification</strong> models from different machine learning libraries, like <strong>sklearn, TMVA, XGBoost</strong>, ...</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used to train a model</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>if <cite>features</cite> aren&#8217;t set (<strong>None</strong>), then all features in the training dataset will be used</li>
<li>Datasets should be <cite>pandas.DataFrame</cite>, not <cite>numpy.array</cite>.
Provided this, you&#8217;ll be able to choose features used in training by setting e.g.
<cite>features=[&#8216;mass&#8217;, &#8216;momentum&#8217;]</cite> in the constructor.</li>
<li>It works fine with <cite>numpy.array</cite> as well, but in this case all the features will be used.</li>
<li>Classes values must be from 0 to n_classes-1!</li>
</ul>
</div>
<dl class="method">
<dt id="rep.estimators.interface.Classifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.fit_lds">
<code class="descname">fit_lds</code><span class="sig-paren">(</span><em>lds</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.fit_lds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.fit_lds" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classifier on the specific type of dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lds</strong> (<a class="reference internal" href="data.html#rep.data.storage.LabeledDataStorage" title="rep.data.storage.LabeledDataStorage"><em>LabeledDataStorage</em></a>) &#8211; data</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.get_feature_importances">
<code class="descname">get_feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.get_feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.get_feature_importances" title="Permalink to this definition">¶</a></dt>
<dd><p>Return features importance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame with <cite>index=self.features</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Classifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="docutils">
<dt>deep: boolean, optional</dt>
<dd>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</dd>
</dl>
<dl class="docutils">
<dt>params <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any</span></dt>
<dd>Parameter names mapped to their values.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict labels for all samples in the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with integer labels</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Classifier.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True labels for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>Mean accuracy of self.predict(X) wrt. y.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Classifier.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<p>self</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for data for each class label on each stage (i.e. for boosting algorithms).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">iterator</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.test_on">
<code class="descname">test_on</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.test_on"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.test_on" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare classification report for a single classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">ClassificationReport</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Classifier.test_on_lds">
<code class="descname">test_on_lds</code><span class="sig-paren">(</span><em>lds</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Classifier.test_on_lds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Classifier.test_on_lds" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare a classification report for a single classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lds</strong> (<a class="reference internal" href="data.html#rep.data.storage.LabeledDataStorage" title="rep.data.storage.LabeledDataStorage"><em>LabeledDataStorage</em></a>) &#8211; data</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">ClassificationReport</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.interface.Regressor">
<em class="property">class </em><code class="descclassname">rep.estimators.interface.</code><code class="descname">Regressor</code><span class="sig-paren">(</span><em>features=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.BaseEstimator</span></code>, <code class="xref py py-class docutils literal"><span class="pre">sklearn.base.RegressorMixin</span></code></p>
<p>Interface to train different <strong>regression</strong> models from different machine learning libraries, like <strong>sklearn, TMVA, XGBoost</strong>, ...</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used to train a model</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<ul class="last simple">
<li>if <cite>features</cite> aren&#8217;t set (<strong>None</strong>), then all features in the training dataset will be used</li>
<li>Datasets should be <cite>pandas.DataFrame</cite>, not <cite>numpy.array</cite>.
Provided this, you&#8217;ll be able to choose features used in training by setting e.g.
<cite>features=[&#8216;mass&#8217;, &#8216;momentum&#8217;]</cite> in the constructor.</li>
<li>It works fine with <cite>numpy.array</cite> as well, but in this case all the features will be used.</li>
</ul>
</div>
<dl class="method">
<dt id="rep.estimators.interface.Regressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.fit_lds">
<code class="descname">fit_lds</code><span class="sig-paren">(</span><em>lds</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.fit_lds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.fit_lds" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a regression model on the specific type of dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lds</strong> (<a class="reference internal" href="data.html#rep.data.storage.LabeledDataStorage" title="rep.data.storage.LabeledDataStorage"><em>LabeledDataStorage</em></a>) &#8211; data</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">self</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.get_feature_importances">
<code class="descname">get_feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.get_feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.get_feature_importances" title="Permalink to this definition">¶</a></dt>
<dd><p>Get features importances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame with <cite>index=self.features</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Regressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="docutils">
<dt>deep: boolean, optional</dt>
<dd>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</dd>
</dl>
<dl class="docutils">
<dt>params <span class="classifier-delimiter">:</span> <span class="classifier">mapping of string to any</span></dt>
<dd>Parameter names mapped to their values.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Regressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) ** 2).sum().
Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples, n_features)</span></dt>
<dd>Test samples.</dd>
<dt>y <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = (n_samples) or (n_samples, n_outputs)</span></dt>
<dd>True values for X.</dd>
<dt>sample_weight <span class="classifier-delimiter">:</span> <span class="classifier">array-like, shape = [n_samples], optional</span></dt>
<dd>Sample weights.</dd>
</dl>
<dl class="docutils">
<dt>score <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>R^2 of self.predict(X) wrt. y.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#rep.estimators.interface.Regressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<p>self</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts values for data on each stage (i.e. for boosting algorithms).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">iterator</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.test_on">
<code class="descname">test_on</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.test_on"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.test_on" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare a regression report for a single regressor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values of samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">RegressionReport</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.interface.Regressor.test_on_lds">
<code class="descname">test_on_lds</code><span class="sig-paren">(</span><em>lds</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/interface.html#Regressor.test_on_lds"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.interface.Regressor.test_on_lds" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepare a regression report for a single regressor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lds</strong> (<a class="reference internal" href="data.html#rep.data.storage.LabeledDataStorage" title="rep.data.storage.LabeledDataStorage"><em>LabeledDataStorage</em></a>) &#8211; data</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">RegressionReport</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.sklearn">
<span id="sklearn-classifier-and-regressor"></span><h2>Sklearn classifier and regressor<a class="headerlink" href="#module-rep.estimators.sklearn" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="#rep.estimators.sklearn.SklearnClassifier" title="rep.estimators.sklearn.SklearnClassifier"><code class="xref py py-class docutils literal"><span class="pre">SklearnClassifier</span></code></a> and <a class="reference internal" href="#rep.estimators.sklearn.SklearnRegressor" title="rep.estimators.sklearn.SklearnRegressor"><code class="xref py py-class docutils literal"><span class="pre">SklearnRegressor</span></code></a> are wrappers for algorithms from scikit-learn.</p>
<p>From user perspective, wrapped sklearn model behaves in the same way as non-wrapped,
but has one additional parameter <em>features</em> to choose necessary columns to use in training.</p>
<p>Typically, models from <strong>REP</strong> are used with <cite>pandas.DataFrames</cite>,
which makes it possible to name needed variables or give some variables specific role in the training.</p>
<p>If data has <code class="xref py py-class docutils literal"><span class="pre">numpy.array</span></code> type then behaviour will be the same as in sklearn.
For complete list of the available algorithms, see <a class="reference external" href="http://scikit-learn.org/stable/modules/classes.html">sklearn API</a>.</p>
<dl class="class">
<dt id="rep.estimators.sklearn.SklearnClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.sklearn.</code><code class="descname">SklearnClassifier</code><span class="sig-paren">(</span><em>clf</em>, <em>features=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.sklearn.SklearnBase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>SklearnClassifier is a wrapper over sklearn-like <strong>classifiers</strong>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>clf</strong> (<em>sklearn.BaseEstimator</em>) &#8211; classifier to train. Should be sklearn-compatible.</li>
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.sklearn.SklearnClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; target of training, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">if sklearn classifier doesn&#8217;t support <cite>sample_weight</cite>, then put <cite>sample_weight=None</cite>,
otherwise exception will be thrown.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.sklearn.SklearnClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnClassifier.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict labels for all samples in the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with integer labels</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.sklearn.SklearnClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.sklearn.SklearnClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for data for each class label on each stage (i.e. for boosting algorithms).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">iterator</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.sklearn.SklearnRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.sklearn.</code><code class="descname">SklearnRegressor</code><span class="sig-paren">(</span><em>clf</em>, <em>features=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.sklearn.SklearnBase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>SklearnRegressor is a wrapper over sklearn-like <strong>regressors</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>clf</strong> (<em>sklearn.BaseEstimator</em>) &#8211; classifier to train. Should be sklearn-compatible.</li>
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.sklearn.SklearnRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; target of training, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">if sklearn classifier doesn&#8217;t support <cite>sample_weight</cite>, then put <cite>sample_weight=None</cite>,
otherwise exception will be thrown.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.sklearn.SklearnRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.sklearn.SklearnRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/sklearn.html#SklearnRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.sklearn.SklearnRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts values for data on each stage (i.e. for boosting algorithms).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">iterator</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.tmva">
<span id="tmva-classifier-and-regressor"></span><h2>TMVA classifier and regressor<a class="headerlink" href="#module-rep.estimators.tmva" title="Permalink to this headline">¶</a></h2>
<p>These classes are wrappers for physics machine learning library TMVA used .root format files (c++ library).
Now you can simply use it in python. TMVA contains classification and regression algorithms, including neural networks.
See <a class="reference external" href="http://mirror.yandex.ru/gentoo-distfiles/distfiles/TMVAUsersGuide-v4.03.pdf">TMVA guide</a>
for the list of the available algorithms and parameters.</p>
<dl class="class">
<dt id="rep.estimators.tmva.TMVAClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.tmva.</code><code class="descname">TMVAClassifier</code><span class="sig-paren">(</span><em>method='kBDT'</em>, <em>features=None</em>, <em>factory_options=''</em>, <em>sigmoid_function='bdt'</em>, <em>**method_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.tmva.TMVABase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>Implements classification models from TMVA library: CERN library for machine learning.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>method</strong> (<em>str</em>) &#8211; algorithm method (default=&#8217;kBDT&#8217;)</li>
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>factory_options</strong> (<em>str</em>) &#8211; <p>system options, including data transformations before training, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="s2">&quot;!V:!Silent:Color:Transformations=I;D;P;G,D&quot;</span>
</pre></div>
</div>
</li>
<li><strong>sigmoid_function</strong> (<em>str</em>) &#8211; <p>function which is used to convert TMVA output to probabilities;</p>
<ul>
<li><em>identity</em> (use for svm, mlp) &#8212; do not transform the output, use this value for methods returning class probabilities</li>
<li><em>sigmoid</em> &#8212; sigmoid transformation, use it if output varies in range [-infinity, +infinity]</li>
<li><em>bdt</em> (for the BDT algorithms output varies in range [-1, 1])</li>
<li><em>sig_eff=0.4</em> &#8212; for the rectangular cut optimization methods,
for instance, here 0.4 will be used as a signal efficiency to evaluate MVA,
(put any float number from [0, 1])</li>
</ul>
</li>
<li><strong>method_parameters</strong> (<em>dict</em>) &#8211; classifier options, example: <cite>NTrees=100</cite>, <cite>BoostType=&#8217;Grad&#8217;</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>TMVA doesn&#8217;t support <em>staged_predict_proba()</em> and <em>feature_importances__</em>.</p>
<p class="last">TMVA doesn&#8217;t support multiclassification, only two-class classification.</p>
</div>
<p><a class="reference external" href="http://mirror.yandex.ru/gentoo-distfiles/distfiles/TMVAUsersGuide-v4.03.pdf">TMVA guide</a>.</p>
<dl class="method">
<dt id="rep.estimators.tmva.TMVAClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVAClassifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict, parameter names mapped to their values.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVAClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVAClassifier.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>params</strong> (<em>dict</em>) &#8211; parameters to set in the model</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVAClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVAClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVAClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported for the TMVA library (<strong>AttributeError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.tmva.TMVARegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.tmva.</code><code class="descname">TMVARegressor</code><span class="sig-paren">(</span><em>method='kBDT'</em>, <em>features=None</em>, <em>factory_options=''</em>, <em>**method_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.tmva.TMVABase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>Implements regression models from TMVA library: CERN library for machine learning.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>method</strong> (<em>str</em>) &#8211; algorithm method (default=&#8217;kBDT&#8217;)</li>
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>factory_options</strong> (<em>str</em>) &#8211; <p>system options, including data transformations before training, for example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="s2">&quot;!V:!Silent:Color:Transformations=I;D;P;G,D&quot;</span>
</pre></div>
</div>
</li>
<li><strong>method_parameters</strong> (<em>dict</em>) &#8211; regressor options, for example: <cite>NTrees=100</cite>, <cite>BoostType=&#8217;Grad&#8217;</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">TMVA doesn&#8217;t support <em>staged_predict()</em> and <em>feature_importances__</em>.</p>
</div>
<p><a class="reference external" href="http://mirror.yandex.ru/gentoo-distfiles/distfiles/TMVAUsersGuide-v4.03.pdf">TMVA guide</a></p>
<dl class="method">
<dt id="rep.estimators.tmva.TMVARegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVARegressor.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor.get_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict, parameter names mapped to their values.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVARegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVARegressor.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>params</strong> (<em>dict</em>) &#8211; parameters to set in the model</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.tmva.TMVARegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/tmva.html#TMVARegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.tmva.TMVARegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported for the TMVA library (<strong>AttributeError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.xgboost">
<span id="xgboost-classifier-and-regressor"></span><h2>XGBoost classifier and regressor<a class="headerlink" href="#module-rep.estimators.xgboost" title="Permalink to this headline">¶</a></h2>
<p>These classes are wrappers for <a class="reference external" href="https://github.com/dmlc/xgboost">XGBoost library</a>.</p>
<dl class="class">
<dt id="rep.estimators.xgboost.XGBoostBase">
<em class="property">class </em><code class="descclassname">rep.estimators.xgboost.</code><code class="descname">XGBoostBase</code><span class="sig-paren">(</span><em>n_estimators=100</em>, <em>nthreads=16</em>, <em>num_feature=None</em>, <em>gamma=None</em>, <em>eta=0.3</em>, <em>max_depth=6</em>, <em>scale_pos_weight=1.0</em>, <em>min_child_weight=1.0</em>, <em>subsample=1.0</em>, <em>colsample=1.0</em>, <em>base_score=0.5</em>, <em>verbose=0</em>, <em>missing=-999.0</em>, <em>random_state=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A base class for the XGBoostClassifier and XGBoostRegressor. XGBoost tree booster is used.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_estimators</strong> (<em>int</em>) &#8211; number of trees built.</li>
<li><strong>nthreads</strong> (<em>int</em>) &#8211; number of parallel threads used to run XGBoost.</li>
<li><strong>num_feature</strong> (<em>None or int</em>) &#8211; feature dimension used in boosting, set to maximum dimension of the feature
(set automatically by XGBoost, no need to be set by user).</li>
<li><strong>gamma</strong> (<em>None or float</em>) &#8211; minimum loss reduction required to make a further partition on a leaf node of the tree.
The larger, the more conservative the algorithm will be.</li>
<li><strong>eta</strong> (<em>float</em>) &#8211; (or learning rate) step size shrinkage used in update to prevent overfitting.
After each boosting step, we can directly get the weights of new features
and eta actually shrinkages the feature weights to make the boosting process more conservative.</li>
<li><strong>max_depth</strong> (<em>int</em>) &#8211; maximum depth of a tree.</li>
<li><strong>scale_pos_weight</strong> (<em>float</em>) &#8211; ration of weights of the class 1 to the weights of the class 0.</li>
<li><strong>min_child_weight</strong> (<em>float</em>) &#8211; <p>minimum sum of instance weight (hessian) needed in a child.
If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight,
then the building process will give up further partitioning.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">weights are normalized so that mean=1 before fitting. Roughly min_child_weight is equal to the number of events.</p>
</div>
</li>
<li><strong>subsample</strong> (<em>float</em>) &#8211; subsample ratio of the training instance.
Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees
and this will prevent overfitting.</li>
<li><strong>colsample</strong> (<em>float</em>) &#8211; subsample ratio of columns when constructing each tree.</li>
<li><strong>base_score</strong> (<em>float</em>) &#8211; the initial prediction score of all instances, global bias.</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
<li><strong>verbose</strong> (<em>boot</em>) &#8211; if 1, will print messages during training</li>
<li><strong>missing</strong> (<em>float</em>) &#8211; the number considered by XGBoost as missing value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="rep.estimators.xgboost.XGBoostBase.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#rep.estimators.xgboost.XGBoostBase.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn-way of returning feature importance.
This returned as numpy.array, assuming that initially passed train_features=None</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostBase.get_feature_importances">
<code class="descname">get_feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostBase.get_feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostBase.get_feature_importances" title="Permalink to this definition">¶</a></dt>
<dd><p>Get features importances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame with <cite>index=self.features</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.xgboost.XGBoostClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.xgboost.</code><code class="descname">XGBoostClassifier</code><span class="sig-paren">(</span><em>features=None</em>, <em>n_estimators=100</em>, <em>nthreads=16</em>, <em>num_feature=None</em>, <em>gamma=None</em>, <em>eta=0.3</em>, <em>max_depth=6</em>, <em>scale_pos_weight=1.0</em>, <em>min_child_weight=1.0</em>, <em>subsample=1.0</em>, <em>colsample=1.0</em>, <em>base_score=0.5</em>, <em>verbose=0</em>, <em>missing=-999.0</em>, <em>random_state=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.xgboost.XGBoostBase" title="rep.estimators.xgboost.XGBoostBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.xgboost.XGBoostBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>Implements classification model from XGBoost library. 
A base class for the XGBoostClassifier and XGBoostRegressor. XGBoost tree booster is used.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_estimators</strong> (<em>int</em>) &#8211; number of trees built.</li>
<li><strong>nthreads</strong> (<em>int</em>) &#8211; number of parallel threads used to run XGBoost.</li>
<li><strong>num_feature</strong> (<em>None or int</em>) &#8211; feature dimension used in boosting, set to maximum dimension of the feature
(set automatically by XGBoost, no need to be set by user).</li>
<li><strong>gamma</strong> (<em>None or float</em>) &#8211; minimum loss reduction required to make a further partition on a leaf node of the tree.
The larger, the more conservative the algorithm will be.</li>
<li><strong>eta</strong> (<em>float</em>) &#8211; (or learning rate) step size shrinkage used in update to prevent overfitting.
After each boosting step, we can directly get the weights of new features
and eta actually shrinkages the feature weights to make the boosting process more conservative.</li>
<li><strong>max_depth</strong> (<em>int</em>) &#8211; maximum depth of a tree.</li>
<li><strong>scale_pos_weight</strong> (<em>float</em>) &#8211; ration of weights of the class 1 to the weights of the class 0.</li>
<li><strong>min_child_weight</strong> (<em>float</em>) &#8211; <p>minimum sum of instance weight (hessian) needed in a child.
If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight,
then the building process will give up further partitioning.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">weights are normalized so that mean=1 before fitting. Roughly min_child_weight is equal to the number of events.</p>
</div>
</li>
<li><strong>subsample</strong> (<em>float</em>) &#8211; subsample ratio of the training instance.
Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees
and this will prevent overfitting.</li>
<li><strong>colsample</strong> (<em>float</em>) &#8211; subsample ratio of columns when constructing each tree.</li>
<li><strong>base_score</strong> (<em>float</em>) &#8211; the initial prediction score of all instances, global bias.</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
<li><strong>verbose</strong> (<em>boot</em>) &#8211; if 1, will print messages during training</li>
<li><strong>missing</strong> (<em>float</em>) &#8211; the number considered by XGBoost as missing value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>step=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for data for each class label on each stage..</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>step</strong> (<em>int</em>) &#8211; step for returned iterations (None by default).
XGBoost does not implement this functionality and we need to
predict from the beginning each time.
With <cite>None</cite> passed step is chosen to have 10 points in the learning curve.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">iterator</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.xgboost.XGBoostRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.xgboost.</code><code class="descname">XGBoostRegressor</code><span class="sig-paren">(</span><em>features=None</em>, <em>n_estimators=100</em>, <em>nthreads=16</em>, <em>num_feature=None</em>, <em>gamma=None</em>, <em>eta=0.3</em>, <em>max_depth=6</em>, <em>min_child_weight=1.0</em>, <em>subsample=1.0</em>, <em>colsample=1.0</em>, <em>objective_type='linear'</em>, <em>base_score=0.5</em>, <em>verbose=0</em>, <em>missing=-999.0</em>, <em>random_state=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.xgboost.XGBoostBase" title="rep.estimators.xgboost.XGBoostBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.xgboost.XGBoostBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>Implements regression model from XGBoost library. 
A base class for the XGBoostClassifier and XGBoostRegressor. XGBoost tree booster is used.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_estimators</strong> (<em>int</em>) &#8211; number of trees built.</li>
<li><strong>nthreads</strong> (<em>int</em>) &#8211; number of parallel threads used to run XGBoost.</li>
<li><strong>num_feature</strong> (<em>None or int</em>) &#8211; feature dimension used in boosting, set to maximum dimension of the feature
(set automatically by XGBoost, no need to be set by user).</li>
<li><strong>gamma</strong> (<em>None or float</em>) &#8211; minimum loss reduction required to make a further partition on a leaf node of the tree.
The larger, the more conservative the algorithm will be.</li>
<li><strong>eta</strong> (<em>float</em>) &#8211; (or learning rate) step size shrinkage used in update to prevent overfitting.
After each boosting step, we can directly get the weights of new features
and eta actually shrinkages the feature weights to make the boosting process more conservative.</li>
<li><strong>max_depth</strong> (<em>int</em>) &#8211; maximum depth of a tree.</li>
<li><strong>scale_pos_weight</strong> (<em>float</em>) &#8211; ration of weights of the class 1 to the weights of the class 0.</li>
<li><strong>min_child_weight</strong> (<em>float</em>) &#8211; <p>minimum sum of instance weight (hessian) needed in a child.
If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight,
then the building process will give up further partitioning.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">weights are normalized so that mean=1 before fitting. Roughly min_child_weight is equal to the number of events.</p>
</div>
</li>
<li><strong>subsample</strong> (<em>float</em>) &#8211; subsample ratio of the training instance.
Setting it to 0.5 means that XGBoost randomly collected half of the data instances to grow trees
and this will prevent overfitting.</li>
<li><strong>colsample</strong> (<em>float</em>) &#8211; subsample ratio of columns when constructing each tree.</li>
<li><strong>base_score</strong> (<em>float</em>) &#8211; the initial prediction score of all instances, global bias.</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
<li><strong>verbose</strong> (<em>boot</em>) &#8211; if 1, will print messages during training</li>
<li><strong>missing</strong> (<em>float</em>) &#8211; the number considered by XGBoost as missing value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.xgboost.XGBoostRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em>, <em>step=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/xgboost.html#XGBoostRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.xgboost.XGBoostRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts values for data on each stage.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> &#8211; pandas.DataFrame of shape [n_samples, n_features]</li>
<li><strong>step</strong> (<em>int</em>) &#8211; step for returned iterations (None by default).
XGBoost does not implement this functionality and we need to
predict from the beginning each time.
With <cite>None</cite> passed step is chosen to have 10 points in the learning curve.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">iterator</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.theanets">
<span id="theanets-classifier-and-regressor"></span><h2>Theanets classifier and regressor<a class="headerlink" href="#module-rep.estimators.theanets" title="Permalink to this headline">¶</a></h2>
<p>These classes are wrappers for <a class="reference external" href="http://theanets.readthedocs.org/">theanets library</a> &#8212; a neural network python library.</p>
<dl class="class">
<dt id="rep.estimators.theanets.TheanetsBase">
<em class="property">class </em><code class="descclassname">rep.estimators.theanets.</code><code class="descname">TheanetsBase</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>input_layer=-1</em>, <em>output_layer=-1</em>, <em>hidden_activation='logistic'</em>, <em>output_activation='linear'</em>, <em>input_noise=0</em>, <em>hidden_noise=0</em>, <em>input_dropout=0</em>, <em>hidden_dropout=0</em>, <em>decode_from=1</em>, <em>weight_l1=0.01</em>, <em>weight_l2=0.01</em>, <em>scaler='standard'</em>, <em>trainers=None</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A base class for the estimators from Theanets library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>None or list(str)</em>) &#8211; list of features to train model</li>
<li><strong>layers</strong> (<em>sequence of int, tuple, dict</em>) &#8211; a sequence of values specifying the <strong>hidden</strong> layer configuration for the network.
For more information see <a class="reference external" href="http://theanets.readthedocs.org/en/latest/creating.html#creating-specifying-layers">Specifying layers</a>
in the theanets documentation.
Note that theanets <cite>layers</cite> parameter includes input and output layers in the sequence as well.</li>
<li><strong>input_layer</strong> (<em>int</em>) &#8211; size of the input layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>output_layer</strong> (<em>int</em>) &#8211; size of the output layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>hidden_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the hidden network layers by default</li>
<li><strong>output_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the output layer by default</li>
<li><strong>input_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into input</li>
<li><strong>hidden_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into hidden unit activation output</li>
<li><strong>input_dropouts</strong> (<em>float</em>) &#8211; proportion of the input units to randomly set to 0; it ranges [0, 1]</li>
<li><strong>hidden_dropouts</strong> (<em>float</em>) &#8211; proportion of hidden unit activations to randomly set to 0; it ranges [0, 1]</li>
<li><strong>decode_from</strong> (<em>int</em>) &#8211; any of the hidden layers can be tapped at the output. Just specify a value greater than
1 to tap the last N hidden layers. The default is 1, which decodes from just the last layer.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>trainers</strong> (<em>list[dict] or None</em>) &#8211; <p>parameters to specify training algorithm(s), for example:</p>
<p>trainers=[{&#8216;algo&#8217;: sgd, &#8216;momentum&#8217;: 0.2}, {&#8216;algo&#8217;: &#8216;nag&#8217;}]</p>
</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>For more information on the available trainers and their parameters see this <a class="reference external" href="http://theanets.readthedocs.org/en/latest/training.html">page</a>.</p>
<dl class="method">
<dt id="rep.estimators.theanets.TheanetsBase.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsBase.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsBase.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification/regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weights for samples &#8212; array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsBase.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>keep_trainer=True</em>, <em>**trainer</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsBase.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsBase.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the estimator by training the existing estimator again.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weights for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>keep_trainer</strong> (<em>bool</em>) &#8211; True if the trainer is not stored in self.trainers.
If True, will add it to the list of the estimators.</li>
<li><strong>trainer</strong> (<em>dict</em>) &#8211; parameters of the training algorithm we want to use now</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsBase.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsBase.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsBase.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of the estimator. Deep parameters of trainers and scaler can be accessed,
for instance:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">trainers__0</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;algo&#39;</span><span class="p">:</span> <span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">}</span>
<span class="n">trainers__0_algo</span> <span class="o">=</span> <span class="s1">&#39;sgd&#39;</span>
<span class="n">layers__1</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">scaler__use_std</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>params</strong> (<em>dict</em>) &#8211; parameters to set in the model</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.theanets.TheanetsClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.theanets.</code><code class="descname">TheanetsClassifier</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>input_layer=-1</em>, <em>output_layer=-1</em>, <em>hidden_activation='logistic'</em>, <em>output_activation='linear'</em>, <em>input_noise=0</em>, <em>hidden_noise=0</em>, <em>input_dropout=0</em>, <em>hidden_dropout=0</em>, <em>decode_from=1</em>, <em>weight_l1=0.01</em>, <em>weight_l2=0.01</em>, <em>scaler='standard'</em>, <em>trainers=None</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.theanets.TheanetsBase" title="rep.estimators.theanets.TheanetsBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.theanets.TheanetsBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>Implements a classification model from the Theanets library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>None or list(str)</em>) &#8211; list of features to train model</li>
<li><strong>layers</strong> (<em>sequence of int, tuple, dict</em>) &#8211; <p>a sequence of values specifying the <strong>hidden</strong> layer configuration for the network.
For more information see <a class="reference external" href="http://theanets.readthedocs.org/en/latest/creating.html#creating-specifying-layers">Specifying layers</a>
in the theanets documentation.
Note that theanets <cite>layers</cite> parameter includes input and output layers in the sequence as well.</p>
</li>
<li><strong>input_layer</strong> (<em>int</em>) &#8211; size of the input layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>output_layer</strong> (<em>int</em>) &#8211; size of the output layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>hidden_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the hidden network layers by default</li>
<li><strong>output_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the output layer by default</li>
<li><strong>input_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into input</li>
<li><strong>hidden_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into hidden unit activation output</li>
<li><strong>input_dropouts</strong> (<em>float</em>) &#8211; proportion of the input units to randomly set to 0; it ranges [0, 1]</li>
<li><strong>hidden_dropouts</strong> (<em>float</em>) &#8211; proportion of hidden unit activations to randomly set to 0; it ranges [0, 1]</li>
<li><strong>decode_from</strong> (<em>int</em>) &#8211; any of the hidden layers can be tapped at the output. Just specify a value greater than
1 to tap the last N hidden layers. The default is 1, which decodes from just the last layer.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>trainers</strong> (<em>list[dict] or None</em>) &#8211; <p>parameters to specify training algorithm(s), for example:</p>
<p>trainers=[{&#8216;algo&#8217;: sgd, &#8216;momentum&#8217;: 0.2}, {&#8216;algo&#8217;: &#8216;nag&#8217;}]</p>
</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>For more information on the available trainers and their parameters see this <a class="reference external" href="http://theanets.readthedocs.org/en/latest/training.html">page</a>.</p>
<dl class="method">
<dt id="rep.estimators.theanets.TheanetsClassifier.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>keep_trainer=True</em>, <em>**trainer</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsClassifier.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsClassifier.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the estimator by training the existing estimator again.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weights for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>keep_trainer</strong> (<em>bool</em>) &#8211; True if the trainer is not stored in self.trainers.
If True, will add it to the list of the estimators.</li>
<li><strong>trainer</strong> (<em>dict</em>) &#8211; parameters of the training algorithm we want to use now</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported in the Theanets (<strong>NotImplementedError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.theanets.TheanetsRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.theanets.</code><code class="descname">TheanetsRegressor</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>input_layer=-1</em>, <em>output_layer=-1</em>, <em>hidden_activation='logistic'</em>, <em>output_activation='linear'</em>, <em>input_noise=0</em>, <em>hidden_noise=0</em>, <em>input_dropout=0</em>, <em>hidden_dropout=0</em>, <em>decode_from=1</em>, <em>weight_l1=0.01</em>, <em>weight_l2=0.01</em>, <em>scaler='standard'</em>, <em>trainers=None</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.theanets.TheanetsBase" title="rep.estimators.theanets.TheanetsBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.theanets.TheanetsBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>Implements a regression model from the Theanets library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>None or list(str)</em>) &#8211; list of features to train model</li>
<li><strong>layers</strong> (<em>sequence of int, tuple, dict</em>) &#8211; <p>a sequence of values specifying the <strong>hidden</strong> layer configuration for the network.
For more information see <a class="reference external" href="http://theanets.readthedocs.org/en/latest/creating.html#creating-specifying-layers">Specifying layers</a>
in the theanets documentation.
Note that theanets <cite>layers</cite> parameter includes input and output layers in the sequence as well.</p>
</li>
<li><strong>input_layer</strong> (<em>int</em>) &#8211; size of the input layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>output_layer</strong> (<em>int</em>) &#8211; size of the output layer. If it equals -1, the size is taken from the training dataset</li>
<li><strong>hidden_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the hidden network layers by default</li>
<li><strong>output_activation</strong> (<em>str</em>) &#8211; the name of an activation function to use on the output layer by default</li>
<li><strong>input_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into input</li>
<li><strong>hidden_noise</strong> (<em>float</em>) &#8211; standard deviation of desired noise to inject into hidden unit activation output</li>
<li><strong>input_dropouts</strong> (<em>float</em>) &#8211; proportion of the input units to randomly set to 0; it ranges [0, 1]</li>
<li><strong>hidden_dropouts</strong> (<em>float</em>) &#8211; proportion of hidden unit activations to randomly set to 0; it ranges [0, 1]</li>
<li><strong>decode_from</strong> (<em>int</em>) &#8211; any of the hidden layers can be tapped at the output. Just specify a value greater than
1 to tap the last N hidden layers. The default is 1, which decodes from just the last layer.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>trainers</strong> (<em>list[dict] or None</em>) &#8211; <p>parameters to specify training algorithm(s), for example:</p>
<p>trainers=[{&#8216;algo&#8217;: sgd, &#8216;momentum&#8217;: 0.2}, {&#8216;algo&#8217;: &#8216;nag&#8217;}]</p>
</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>For more information on the available trainers and their parameters see this <a class="reference external" href="http://theanets.readthedocs.org/en/latest/training.html">page</a>.</p>
<dl class="method">
<dt id="rep.estimators.theanets.TheanetsRegressor.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em>, <em>keep_trainer=True</em>, <em>**trainer</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsRegressor.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsRegressor.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the estimator by training the existing estimator again.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weights for samples &#8212; array-like of shape [n_samples]</li>
<li><strong>keep_trainer</strong> (<em>bool</em>) &#8211; True if the trainer is not stored in self.trainers.
If True, will add it to the list of the estimators.</li>
<li><strong>trainer</strong> (<em>dict</em>) &#8211; parameters of the training algorithm we want to use now</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.theanets.TheanetsRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/theanets.html#TheanetsRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.theanets.TheanetsRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported in the Theanets (<strong>NotImplementedError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.neurolab">
<span id="neurolab-classifier-and-regressor"></span><h2>Neurolab classifier and regressor<a class="headerlink" href="#module-rep.estimators.neurolab" title="Permalink to this headline">¶</a></h2>
<p>These classes are wrappers for the <a class="reference external" href="https://pythonhosted.org/neurolab/lib.html">Neurolab library</a> &#8212; a neural network python library.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>To make neurolab reproducible we change global random seed</p>
<div class="last highlight-python"><div class="highlight"><pre><span></span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<dl class="class">
<dt id="rep.estimators.neurolab.NeurolabClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.neurolab.</code><code class="descname">NeurolabClassifier</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>net_type='feed-forward'</em>, <em>initf=&lt;function init_rand&gt;</em>, <em>trainf=None</em>, <em>scaler='standard'</em>, <em>random_state=None</em>, <em>**other_params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.neurolab.NeurolabBase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>Implements a classification model from the Neurolab library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>layers</strong> (<em>list[int]</em>) &#8211; sequence, number of units inside each <strong>hidden</strong> layer.</li>
<li><strong>net_type</strong> (<em>string</em>) &#8211; <p>type of the network; possible values are:</p>
<ul>
<li><cite>feed-forward</cite></li>
<li><cite>competing-layer</cite></li>
<li><cite>learning-vector</cite></li>
<li><cite>elman-recurrent</cite></li>
<li><cite>hemming-recurrent</cite></li>
</ul>
</li>
<li><strong>initf</strong> (<em>anything implementing call(layer), e.g. neurolab.init.* or list[neurolab.init.*] of shape [n_layers]</em>) &#8211; layer initializers</li>
<li><strong>trainf</strong> &#8211; net training function; default value depends on the type of a network</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>random_state</strong> &#8211; this parameter is ignored and is added for uniformity.</li>
<li><strong>kwargs</strong> (<em>dict</em>) &#8211; additional arguments to net <cite>__init__</cite>, varies with different <cite>net_types</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference external" href="https://pythonhosted.org/neurolab/lib.html">Supported training functions and their parameters</a></p>
</div>
<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples &#8212; array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabClassifier.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabClassifier.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabClassifier.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional training of the classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This is not supported in the Neurolab (<strong>AttributeError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.neurolab.NeurolabRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.neurolab.</code><code class="descname">NeurolabRegressor</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>net_type='feed-forward'</em>, <em>initf=&lt;function init_rand&gt;</em>, <em>trainf=None</em>, <em>scaler='standard'</em>, <em>random_state=None</em>, <em>**other_params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">rep.estimators.neurolab.NeurolabBase</span></code>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>Implements a regression model from the Neurolab library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>layers</strong> (<em>list[int]</em>) &#8211; sequence, number of units inside each <strong>hidden</strong> layer.</li>
<li><strong>net_type</strong> (<em>string</em>) &#8211; <p>type of the network; possible values are:</p>
<ul>
<li><cite>feed-forward</cite></li>
<li><cite>competing-layer</cite></li>
<li><cite>learning-vector</cite></li>
<li><cite>elman-recurrent</cite></li>
<li><cite>hemming-recurrent</cite></li>
</ul>
</li>
<li><strong>initf</strong> (<em>anything implementing call(layer), e.g. neurolab.init.* or list[neurolab.init.*] of shape [n_layers]</em>) &#8211; layer initializers</li>
<li><strong>trainf</strong> &#8211; net training function; default value depends on the type of a network</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>random_state</strong> &#8211; this parameter is ignored and is added for uniformity.</li>
<li><strong>kwargs</strong> (<em>dict</em>) &#8211; additional arguments to net <cite>__init__</cite>, varies with different <cite>net_types</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference external" href="https://pythonhosted.org/neurolab/lib.html">Supported training functions and their parameters</a></p>
</div>
<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabRegressor.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabRegressor.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabRegressor.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional training of the regressor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples, array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict values for data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with predicted values</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.neurolab.NeurolabRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/neurolab.html#NeurolabRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.neurolab.NeurolabRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This is not supported in the Neurolab (<strong>AttributeError</strong> will be thrown)</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.pybrain">
<span id="pybrain-classifier-and-regressor"></span><h2>Pybrain classifier and regressor<a class="headerlink" href="#module-rep.estimators.pybrain" title="Permalink to this headline">¶</a></h2>
<p>These classes are wrappers for the <a class="reference external" href="http://pybrain.org/docs/">PyBrain library</a> &#8212; a neural network python library.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">pybrain training isn&#8217;t reproducible
(training with the same parameters produces different neural network each time)</p>
</div>
<dl class="class">
<dt id="rep.estimators.pybrain.PyBrainBase">
<em class="property">class </em><code class="descclassname">rep.estimators.pybrain.</code><code class="descname">PyBrainBase</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>hiddenclass=None</em>, <em>epochs=10</em>, <em>scaler='standard'</em>, <em>use_rprop=False</em>, <em>learningrate=0.01</em>, <em>lrdecay=1.0</em>, <em>momentum=0.0</em>, <em>verbose=False</em>, <em>batchlearning=False</em>, <em>weightdecay=0.0</em>, <em>etaminus=0.5</em>, <em>etaplus=1.2</em>, <em>deltamin=1e-06</em>, <em>deltamax=0.5</em>, <em>delta0=0.1</em>, <em>max_epochs=None</em>, <em>continue_epochs=3</em>, <em>validation_proportion=0.25</em>, <em>random_state=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A base class for the estimator from the PyBrain.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>use_rprop</strong> (<em>bool</em>) &#8211; flag to indicate whether we should use Rprop or SGD trainer</li>
<li><strong>verbose</strong> (<em>bool</em>) &#8211; print train/validation errors.</li>
<li><strong>random_state</strong> &#8211; it is ignored parameter, pybrain training is not reproducible</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Net parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layers</strong> (<em>list[int]</em>) &#8211; indicate how many neurons in each hidden(!) layer; default is 1 hidden layer with 10 neurons</li>
<li><strong>hiddenclass</strong> (<em>list[str]</em>) &#8211; classes of the hidden layers; default is <cite>&#8216;SigmoidLayer&#8217;</cite></li>
<li><strong>params</strong> (<em>dict</em>) &#8211; <p>other net parameters:</p>
<ul>
<li><cite>bias</cite> and <cite>outputbias</cite> (boolean) flags to indicate whether the network should have the corresponding biases,
both default to True;</li>
<li><cite>peepholes</cite> (boolean);</li>
<li><cite>recurrent</cite> (boolean): if the <cite>recurrent</cite> flag is set, a <code class="xref py py-class docutils literal"><span class="pre">RecurrentNetwork</span></code> will be created,
otherwise a <code class="xref py py-class docutils literal"><span class="pre">FeedForwardNetwork</span></code></li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Gradient descent trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>learningrate</strong> (<em>float</em>) &#8211; gives the ratio of which parameters are changed into the direction of the gradient</li>
<li><strong>lrdecay</strong> (<em>float</em>) &#8211; the learning rate decreases by lrdecay, which is used to multiply the learning rate after each training step</li>
<li><strong>momentum</strong> (<em>float</em>) &#8211; the ratio by which the gradient of the last time step is used</li>
<li><strong>batchlearning</strong> (<em>boolean</em>) &#8211; if set, the parameters are updated only at the end of each epoch. Default is False</li>
<li><strong>weightdecay</strong> (<em>float</em>) &#8211; corresponds to the <cite>weightdecay</cite> rate, where 0 is no weight decay at all</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Rprop trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>etaminus</strong> (<em>float</em>) &#8211; factor by which a step width is decreased when overstepping (default=0.5)</li>
<li><strong>etaplus</strong> (<em>float</em>) &#8211; factor by which a step width is increased when following gradient (default=1.2)</li>
<li><strong>delta</strong> (<em>float</em>) &#8211; step width for each weight</li>
<li><strong>deltamin</strong> (<em>float</em>) &#8211; minimum step width (default=1e-6)</li>
<li><strong>deltamax</strong> (<em>float</em>) &#8211; maximum step width (default=5.0)</li>
<li><strong>delta0</strong> (<em>float</em>) &#8211; initial step width (default=0.1)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Training termination parameters</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>epochs</strong> (<em>int</em>) &#8211; number of iterations in training; if &lt; 0 then estimator trains until converge</li>
<li><strong>max_epochs</strong> (<em>int</em>) &#8211; maximum number of epochs the trainer should train if it is given</li>
<li><strong>continue_epochs</strong> (<em>int</em>) &#8211; each time validation error decreases, try for <cite>continue_epochs</cite> epochs to find a better one</li>
<li><strong>validation_proportion</strong> (<em>float</em>) &#8211; the ratio of the dataset that is used for the validation dataset</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Details about parameters <a class="reference external" href="http://pybrain.org/docs/">here</a>.</p>
</div>
<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainBase.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainBase.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainBase.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification/regression model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples &#8212; array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainBase.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainBase.partial_fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainBase.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Additional training of the classification/regression model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; values for samples, array-like of shape [n_samples]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainBase.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainBase.set_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainBase.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of the estimator.</p>
<p>Names of the parameters are the same as in the constructor.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.pybrain.PyBrainClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.pybrain.</code><code class="descname">PyBrainClassifier</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>hiddenclass=None</em>, <em>epochs=10</em>, <em>scaler='standard'</em>, <em>use_rprop=False</em>, <em>learningrate=0.01</em>, <em>lrdecay=1.0</em>, <em>momentum=0.0</em>, <em>verbose=False</em>, <em>batchlearning=False</em>, <em>weightdecay=0.0</em>, <em>etaminus=0.5</em>, <em>etaplus=1.2</em>, <em>deltamin=1e-06</em>, <em>deltamax=0.5</em>, <em>delta0=0.1</em>, <em>max_epochs=None</em>, <em>continue_epochs=3</em>, <em>validation_proportion=0.25</em>, <em>random_state=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.pybrain.PyBrainBase" title="rep.estimators.pybrain.PyBrainBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.pybrain.PyBrainBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>Implements a classification model from the PyBrain library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>use_rprop</strong> (<em>bool</em>) &#8211; flag to indicate whether we should use Rprop or SGD trainer</li>
<li><strong>verbose</strong> (<em>bool</em>) &#8211; print train/validation errors.</li>
<li><strong>random_state</strong> &#8211; it is ignored parameter, pybrain training is not reproducible</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Net parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layers</strong> (<em>list[int]</em>) &#8211; indicate how many neurons in each hidden(!) layer; default is 1 hidden layer with 10 neurons</li>
<li><strong>hiddenclass</strong> (<em>list[str]</em>) &#8211; classes of the hidden layers; default is <cite>&#8216;SigmoidLayer&#8217;</cite></li>
<li><strong>params</strong> (<em>dict</em>) &#8211; <p>other net parameters:</p>
<ul>
<li><cite>bias</cite> and <cite>outputbias</cite> (boolean) flags to indicate whether the network should have the corresponding biases,
both default to True;</li>
<li><cite>peepholes</cite> (boolean);</li>
<li><cite>recurrent</cite> (boolean): if the <cite>recurrent</cite> flag is set, a <code class="xref py py-class docutils literal"><span class="pre">RecurrentNetwork</span></code> will be created,
otherwise a <code class="xref py py-class docutils literal"><span class="pre">FeedForwardNetwork</span></code></li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Gradient descent trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>learningrate</strong> (<em>float</em>) &#8211; gives the ratio of which parameters are changed into the direction of the gradient</li>
<li><strong>lrdecay</strong> (<em>float</em>) &#8211; the learning rate decreases by lrdecay, which is used to multiply the learning rate after each training step</li>
<li><strong>momentum</strong> (<em>float</em>) &#8211; the ratio by which the gradient of the last time step is used</li>
<li><strong>batchlearning</strong> (<em>boolean</em>) &#8211; if set, the parameters are updated only at the end of each epoch. Default is False</li>
<li><strong>weightdecay</strong> (<em>float</em>) &#8211; corresponds to the <cite>weightdecay</cite> rate, where 0 is no weight decay at all</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Rprop trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>etaminus</strong> (<em>float</em>) &#8211; factor by which a step width is decreased when overstepping (default=0.5)</li>
<li><strong>etaplus</strong> (<em>float</em>) &#8211; factor by which a step width is increased when following gradient (default=1.2)</li>
<li><strong>delta</strong> (<em>float</em>) &#8211; step width for each weight</li>
<li><strong>deltamin</strong> (<em>float</em>) &#8211; minimum step width (default=1e-6)</li>
<li><strong>deltamax</strong> (<em>float</em>) &#8211; maximum step width (default=5.0)</li>
<li><strong>delta0</strong> (<em>float</em>) &#8211; initial step width (default=0.1)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Training termination parameters</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>epochs</strong> (<em>int</em>) &#8211; number of iterations in training; if &lt; 0 then estimator trains until converge</li>
<li><strong>max_epochs</strong> (<em>int</em>) &#8211; maximum number of epochs the trainer should train if it is given</li>
<li><strong>continue_epochs</strong> (<em>int</em>) &#8211; each time validation error decreases, try for <cite>continue_epochs</cite> epochs to find a better one</li>
<li><strong>validation_proportion</strong> (<em>float</em>) &#8211; the ratio of the dataset that is used for the validation dataset</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Details about parameters <a class="reference external" href="http://pybrain.org/docs/">here</a>.</p>
</div>
<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported for PyBrain (<strong>AttributeError</strong> will be thrown).</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.pybrain.PyBrainRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.pybrain.</code><code class="descname">PyBrainRegressor</code><span class="sig-paren">(</span><em>features=None</em>, <em>layers=(10</em>, <em>)</em>, <em>hiddenclass=None</em>, <em>epochs=10</em>, <em>scaler='standard'</em>, <em>use_rprop=False</em>, <em>learningrate=0.01</em>, <em>lrdecay=1.0</em>, <em>momentum=0.0</em>, <em>verbose=False</em>, <em>batchlearning=False</em>, <em>weightdecay=0.0</em>, <em>etaminus=0.5</em>, <em>etaplus=1.2</em>, <em>deltamin=1e-06</em>, <em>deltamax=0.5</em>, <em>delta0=0.1</em>, <em>max_epochs=None</em>, <em>continue_epochs=3</em>, <em>validation_proportion=0.25</em>, <em>random_state=None</em>, <em>**params</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.pybrain.PyBrainBase" title="rep.estimators.pybrain.PyBrainBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.pybrain.PyBrainBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>Implements a regression model from the PyBrain library.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training.</li>
<li><strong>scaler</strong> (<em>str or sklearn-like transformer or False</em>) &#8211; transformer which is applied to the input samples. If it is False, scaling will not be used</li>
<li><strong>use_rprop</strong> (<em>bool</em>) &#8211; flag to indicate whether we should use Rprop or SGD trainer</li>
<li><strong>verbose</strong> (<em>bool</em>) &#8211; print train/validation errors.</li>
<li><strong>random_state</strong> &#8211; it is ignored parameter, pybrain training is not reproducible</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Net parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>layers</strong> (<em>list[int]</em>) &#8211; indicate how many neurons in each hidden(!) layer; default is 1 hidden layer with 10 neurons</li>
<li><strong>hiddenclass</strong> (<em>list[str]</em>) &#8211; classes of the hidden layers; default is <cite>&#8216;SigmoidLayer&#8217;</cite></li>
<li><strong>params</strong> (<em>dict</em>) &#8211; <p>other net parameters:</p>
<ul>
<li><cite>bias</cite> and <cite>outputbias</cite> (boolean) flags to indicate whether the network should have the corresponding biases,
both default to True;</li>
<li><cite>peepholes</cite> (boolean);</li>
<li><cite>recurrent</cite> (boolean): if the <cite>recurrent</cite> flag is set, a <code class="xref py py-class docutils literal"><span class="pre">RecurrentNetwork</span></code> will be created,
otherwise a <code class="xref py py-class docutils literal"><span class="pre">FeedForwardNetwork</span></code></li>
</ul>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Gradient descent trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>learningrate</strong> (<em>float</em>) &#8211; gives the ratio of which parameters are changed into the direction of the gradient</li>
<li><strong>lrdecay</strong> (<em>float</em>) &#8211; the learning rate decreases by lrdecay, which is used to multiply the learning rate after each training step</li>
<li><strong>momentum</strong> (<em>float</em>) &#8211; the ratio by which the gradient of the last time step is used</li>
<li><strong>batchlearning</strong> (<em>boolean</em>) &#8211; if set, the parameters are updated only at the end of each epoch. Default is False</li>
<li><strong>weightdecay</strong> (<em>float</em>) &#8211; corresponds to the <cite>weightdecay</cite> rate, where 0 is no weight decay at all</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Rprop trainer parameters:</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>etaminus</strong> (<em>float</em>) &#8211; factor by which a step width is decreased when overstepping (default=0.5)</li>
<li><strong>etaplus</strong> (<em>float</em>) &#8211; factor by which a step width is increased when following gradient (default=1.2)</li>
<li><strong>delta</strong> (<em>float</em>) &#8211; step width for each weight</li>
<li><strong>deltamin</strong> (<em>float</em>) &#8211; minimum step width (default=1e-6)</li>
<li><strong>deltamax</strong> (<em>float</em>) &#8211; maximum step width (default=5.0)</li>
<li><strong>delta0</strong> (<em>float</em>) &#8211; initial step width (default=0.1)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p><strong>Training termination parameters</strong></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>epochs</strong> (<em>int</em>) &#8211; number of iterations in training; if &lt; 0 then estimator trains until converge</li>
<li><strong>max_epochs</strong> (<em>int</em>) &#8211; maximum number of epochs the trainer should train if it is given</li>
<li><strong>continue_epochs</strong> (<em>int</em>) &#8211; each time validation error decreases, try for <cite>continue_epochs</cite> epochs to find a better one</li>
<li><strong>validation_proportion</strong> (<em>float</em>) &#8211; the ratio of the dataset that is used for the validation dataset</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Details about parameters <a class="reference external" href="http://pybrain.org/docs/">here</a>.</p>
</div>
<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict labels for all samples in the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with integer labels</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.pybrain.PyBrainRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/pybrain.html#PyBrainRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.pybrain.PyBrainRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is not supported for PyBrain (<strong>AttributeError</strong> will be thrown).</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rep.estimators.matrixnet">
<span id="matrixnet-classifier-and-regressor"></span><h2>MatrixNet classifier and regressor<a class="headerlink" href="#module-rep.estimators.matrixnet" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="#rep.estimators.matrixnet.MatrixNetClassifier" title="rep.estimators.matrixnet.MatrixNetClassifier"><code class="xref py py-class docutils literal"><span class="pre">MatrixNetClassifier</span></code></a> and <a class="reference internal" href="#rep.estimators.matrixnet.MatrixNetRegressor" title="rep.estimators.matrixnet.MatrixNetRegressor"><code class="xref py py-class docutils literal"><span class="pre">MatrixNetRegressor</span></code></a> are wrappers for MatrixNet web service - proprietary BDT
developed at Yandex. Think about this as a specific Boosted Decision Tree algorithm which is available as a service.
At this moment MatrixMet is available only for <strong>CERN users</strong>.</p>
<dl class="docutils">
<dt>To use MatrixNet, first acquire token::</dt>
<dd><ul class="first last">
<li><p class="first">Go to <a class="reference external" href="https://yandex-apps.cern.ch/">https://yandex-apps.cern.ch/</a> (login with your CERN-account)</p>
</li>
<li><p class="first">Click <cite>Add token</cite> at the left panel</p>
</li>
<li><p class="first">Choose service <cite>MatrixNet</cite> and click <cite>Create token</cite></p>
</li>
<li><p class="first">Create <cite>~/.rep-matrixnet.config.json</cite> file with the following content
(custom path to the config file can be specified when creating a wrapper object):</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://ml.cern.yandex.net/v1&quot;</span><span class="p">,</span>

    <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;your_token&gt;&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</dd>
</dl>
<dl class="class">
<dt id="rep.estimators.matrixnet.MatrixNetBase">
<em class="property">class </em><code class="descclassname">rep.estimators.matrixnet.</code><code class="descname">MatrixNetBase</code><span class="sig-paren">(</span><em>api_config_file='$HOME/.rep-matrixnet.config.json'</em>, <em>iterations=100</em>, <em>regularization=0.01</em>, <em>intervals=8</em>, <em>max_features_per_iteration=6</em>, <em>features_sample_rate_per_iteration=1.0</em>, <em>training_fraction=0.5</em>, <em>auto_stop=None</em>, <em>sync=True</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Base class for MatrixNetClassifier and MatrixNetRegressor.</p>
<p>This is a wrapper around <strong>MatrixNet (specific BDT)</strong> technology developed at <strong>Yandex</strong>,
which is available for CERN people using authorization.
Trained estimator is downloaded and stored at your computer, so you can use it at any time.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>api_config_file</strong> (<em>str</em>) &#8211; <p>path to the file with remote api configuration in the json format:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://ml.cern.yandex.net/v1&quot;</span><span class="p">,</span> <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;your_token&gt;&quot;</span><span class="p">}</span>
</pre></div>
</div>
</li>
<li><strong>iterations</strong> (<em>int</em>) &#8211; number of constructed trees (default=100)</li>
<li><strong>regularization</strong> (<em>float</em>) &#8211; regularization number (default=0.01)</li>
<li><strong>intervals</strong> (<em>int or dict(str, list)</em>) &#8211; number of bins for features discretization or dict with borders
list for each feature for its discretization (default=8)</li>
<li><strong>max_features_per_iteration</strong> (<em>int</em>) &#8211; depth (default=6, supports 1 &lt;= .. &lt;= 6)</li>
<li><strong>features_sample_rate_per_iteration</strong> (<em>float</em>) &#8211; training features sampling (default=1.0)</li>
<li><strong>training_fraction</strong> (<em>float</em>) &#8211; training rows bagging (default=0.5)</li>
<li><strong>auto_stop</strong> (<em>None or float</em>) &#8211; error value for training pre-stopping</li>
<li><strong>sync</strong> (<em>bool</em>) &#8211; synchronous or asynchronous training on the server</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="rep.estimators.matrixnet.MatrixNetBase.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn-way of returning feature importance.
This returned as numpy.array, &#8216;effect&#8217; column is used among MatrixNet importances.</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetBase.get_feature_importances">
<code class="descname">get_feature_importances</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase.get_feature_importances"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.get_feature_importances" title="Permalink to this definition">¶</a></dt>
<dd><p>Get features importance: <cite>effect</cite>, <cite>efficiency</cite>, <cite>information</cite> characteristics</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame with <cite>index=self.features</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetBase.get_iterations">
<code class="descname">get_iterations</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase.get_iterations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.get_iterations" title="Permalink to this definition">¶</a></dt>
<dd><p>Return number of already constructed trees during training</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">int or None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetBase.resubmit">
<code class="descname">resubmit</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase.resubmit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.resubmit" title="Permalink to this definition">¶</a></dt>
<dd><p>Resubmit training process on the server in case of failing job.</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetBase.synchronize">
<code class="descname">synchronize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase.synchronize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.synchronize" title="Permalink to this definition">¶</a></dt>
<dd><p>Synchronise asynchronic training: wait while training process will be finished on the server</p>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetBase.training_status">
<code class="descname">training_status</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetBase.training_status"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetBase.training_status" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if training has finished on the server</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">bool</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.matrixnet.MatrixNetClassifier">
<em class="property">class </em><code class="descclassname">rep.estimators.matrixnet.</code><code class="descname">MatrixNetClassifier</code><span class="sig-paren">(</span><em>features=None</em>, <em>api_config_file='$HOME/.rep-matrixnet.config.json'</em>, <em>iterations=100</em>, <em>regularization=0.01</em>, <em>intervals=8</em>, <em>max_features_per_iteration=6</em>, <em>features_sample_rate_per_iteration=1.0</em>, <em>training_fraction=0.5</em>, <em>auto_stop=None</em>, <em>sync=True</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.matrixnet.MatrixNetBase" title="rep.estimators.matrixnet.MatrixNetBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.matrixnet.MatrixNetBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Classifier" title="rep.estimators.interface.Classifier"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Classifier</span></code></a></p>
<p>MatrixNet classification model.</p>
<p>This is a wrapper around <strong>MatrixNet (specific BDT)</strong> technology developed at <strong>Yandex</strong>,
which is available for CERN people using authorization.
Trained estimator is downloaded and stored at your computer, so you can use it at any time.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>api_config_file</strong> (<em>str</em>) &#8211; <p>path to the file with remote api configuration in the json format:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://ml.cern.yandex.net/v1&quot;</span><span class="p">,</span> <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;your_token&gt;&quot;</span><span class="p">}</span>
</pre></div>
</div>
</li>
<li><strong>iterations</strong> (<em>int</em>) &#8211; number of constructed trees (default=100)</li>
<li><strong>regularization</strong> (<em>float</em>) &#8211; regularization number (default=0.01)</li>
<li><strong>intervals</strong> (<em>int or dict(str, list)</em>) &#8211; number of bins for features discretization or dict with borders
list for each feature for its discretization (default=8)</li>
<li><strong>max_features_per_iteration</strong> (<em>int</em>) &#8211; depth (default=6, supports 1 &lt;= .. &lt;= 6)</li>
<li><strong>features_sample_rate_per_iteration</strong> (<em>float</em>) &#8211; training features sampling (default=1.0)</li>
<li><strong>training_fraction</strong> (<em>float</em>) &#8211; training rows bagging (default=0.5)</li>
<li><strong>auto_stop</strong> (<em>None or float</em>) &#8211; error value for training pre-stopping</li>
<li><strong>sync</strong> (<em>bool</em>) &#8211; synchronous or asynchronous training on the server</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetClassifier.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetClassifier.predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for each class label for samples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples, n_classes] with probabilities</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetClassifier.staged_predict_proba">
<code class="descname">staged_predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>step=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetClassifier.staged_predict_proba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetClassifier.staged_predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for data for each class label on each stage.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>step</strong> (<em>int</em>) &#8211; step for returned iterations (10 by default).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">iterator</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rep.estimators.matrixnet.MatrixNetRegressor">
<em class="property">class </em><code class="descclassname">rep.estimators.matrixnet.</code><code class="descname">MatrixNetRegressor</code><span class="sig-paren">(</span><em>features=None</em>, <em>api_config_file='$HOME/.rep-matrixnet.config.json'</em>, <em>iterations=100</em>, <em>regularization=0.01</em>, <em>intervals=8</em>, <em>max_features_per_iteration=6</em>, <em>features_sample_rate_per_iteration=1.0</em>, <em>training_fraction=0.5</em>, <em>auto_stop=None</em>, <em>sync=True</em>, <em>random_state=42</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetRegressor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#rep.estimators.matrixnet.MatrixNetBase" title="rep.estimators.matrixnet.MatrixNetBase"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.matrixnet.MatrixNetBase</span></code></a>, <a class="reference internal" href="#rep.estimators.interface.Regressor" title="rep.estimators.interface.Regressor"><code class="xref py py-class docutils literal"><span class="pre">rep.estimators.interface.Regressor</span></code></a></p>
<p>MatrixNet for regression model.</p>
<p>This is a wrapper around <strong>MatrixNet (specific BDT)</strong> technology developed at <strong>Yandex</strong>,
which is available for CERN people using authorization.
Trained estimator is downloaded and stored at your computer, so you can use it at any time.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>features</strong> (<em>list[str] or None</em>) &#8211; features used in training</li>
<li><strong>api_config_file</strong> (<em>str</em>) &#8211; <p>path to the file with remote api configuration in the json format:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://ml.cern.yandex.net/v1&quot;</span><span class="p">,</span> <span class="s2">&quot;token&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;your_token&gt;&quot;</span><span class="p">}</span>
</pre></div>
</div>
</li>
<li><strong>iterations</strong> (<em>int</em>) &#8211; number of constructed trees (default=100)</li>
<li><strong>regularization</strong> (<em>float</em>) &#8211; regularization number (default=0.01)</li>
<li><strong>intervals</strong> (<em>int or dict(str, list)</em>) &#8211; number of bins for features discretization or dict with borders
list for each feature for its discretization (default=8)</li>
<li><strong>max_features_per_iteration</strong> (<em>int</em>) &#8211; depth (default=6, supports 1 &lt;= .. &lt;= 6)</li>
<li><strong>features_sample_rate_per_iteration</strong> (<em>float</em>) &#8211; training features sampling (default=1.0)</li>
<li><strong>training_fraction</strong> (<em>float</em>) &#8211; training rows bagging (default=0.5)</li>
<li><strong>auto_stop</strong> (<em>None or float</em>) &#8211; error value for training pre-stopping</li>
<li><strong>sync</strong> (<em>bool</em>) &#8211; synchronous or asynchronous training on the server</li>
<li><strong>random_state</strong> (<em>None or int or RandomState</em>) &#8211; state for a pseudo random generator</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetRegressor.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a classification model on the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>y</strong> &#8211; labels of samples, array-like of shape [n_samples]</li>
<li><strong>sample_weight</strong> &#8211; weight of samples,
array-like of shape [n_samples] or None if all weights are equal</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">self</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetRegressor.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict labels for all samples in the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy.array of shape [n_samples] with integer labels</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="rep.estimators.matrixnet.MatrixNetRegressor.staged_predict">
<code class="descname">staged_predict</code><span class="sig-paren">(</span><em>X</em>, <em>step=10</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/rep/estimators/matrixnet.html#MatrixNetRegressor.staged_predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#rep.estimators.matrixnet.MatrixNetRegressor.staged_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict probabilities for data for each class label on each stage.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>pandas.DataFrame</em>) &#8211; data of shape [n_samples, n_features]</li>
<li><strong>step</strong> (<em>int</em>) &#8211; step for returned iterations (10 by default).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">iterator</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h3>
<ul>
<li><dl class="first docutils">
<dt>Prepare dataset</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span><span class="o">,</span> <span class="nn">numpy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.utils</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># iris data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Take just two classes instead of three</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">labels</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">labels</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Sklearn classification</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">SklearnClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Using gradient boosting with default settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sk</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">GradientBoostingClassifier</span><span class="p">(),</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Training classifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">sk</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">pred</span>
<span class="go">[[  9.99842983e-01   1.57016893e-04]</span>
<span class="go"> [  1.45163843e-04   9.99854836e-01]</span>
<span class="go"> [  9.99842983e-01   1.57016893e-04]</span>
<span class="go"> [  9.99827693e-01   1.72306607e-04], ..]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">0.99768518518518523</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>TMVA classification</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">TMVAClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tmva</span> <span class="o">=</span> <span class="n">TMVAClassifier</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;kBDT&#39;</span><span class="p">,</span> <span class="n">NTrees</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">Shrinkage</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">nCuts</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">BoostType</span><span class="o">=</span><span class="s1">&#39;Grad&#39;</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tmva</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">tmva</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">pred</span>
<span class="go">[[  9.99991025e-01   8.97546346e-06]</span>
<span class="go"> [  1.14084636e-04   9.99885915e-01]</span>
<span class="go"> [  9.99991009e-01   8.99060302e-06]</span>
<span class="go"> [  9.99798700e-01   2.01300452e-04], ..]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">0.99999999999999989</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>XGBoost classification</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">XGBoostClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># XGBoost with default parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBoostClassifier</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">pred</span>
<span class="go">[[ 0.9983651   0.00163494]</span>
<span class="go"> [ 0.00170585  0.99829417]</span>
<span class="go"> [ 0.99845636  0.00154361]</span>
<span class="go"> [ 0.96618336  0.03381656], ..]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">0.99768518518518512</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="regression">
<h3>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h3>
<ul>
<li><dl class="first docutils">
<dt>Prepare dataset</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.utils</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span><span class="o">,</span> <span class="nn">numpy</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># diabetes data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diabetes</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_diabetes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">number</span> <span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">diabetes</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">diabetes</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">diabetes</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Sklearn regression</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">SklearnRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Using gradient boosting with default settings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sk</span> <span class="o">=</span> <span class="n">SklearnRegressor</span><span class="p">(</span><span class="n">GradientBoostingRegressor</span><span class="p">(),</span> <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Training classifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">sk</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="go">60.666009962879265</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>TMVA regression</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">TMVARegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tmva</span> <span class="o">=</span> <span class="n">TMVARegressor</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;kBDT&#39;</span><span class="p">,</span> <span class="n">NTrees</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">Shrinkage</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">nCuts</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">BoostType</span><span class="o">=</span><span class="s1">&#39;Grad&#39;</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tmva</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">tmva</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="go">73.74191838418254</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>XGBoost regression</dt>
<dd><div class="first last highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">XGBoostRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># XGBoost with default parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBoostRegressor</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="go">65.557743652940133</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
</div>
</div>
<div class="section" id="compatible-libraries">
<h2>Compatible libraries<a class="headerlink" href="#compatible-libraries" title="Permalink to this headline">¶</a></h2>
<p>REP can deal with any library which supports scikit-learn interface.</p>
<p>Examples of compatible libraries: <a class="reference external" href="http://pythonhosted.org/nolearn/">nolearn</a>, <a class="reference external" href="https://github.com/tensorflow/skflow/">skflow</a>, <a class="reference external" href="http://gplearn.readthedocs.org/en/latest/">gplearn</a> and <a class="reference external" href="https://arogozhnikov.github.io/hep_ml/">hep_ml</a>.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metaml.html" class="btn btn-neutral float-right" title="Meta Machine Learning" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Welcome to REP’s documentation!" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014-2015, Yandex.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.6.7',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>